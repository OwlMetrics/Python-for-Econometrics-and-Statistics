{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Performance Improvement\n",
    "A typical programming procedure involves a sequence of three steps associated with their respective interim goals, i.e., \"make it run\" $\\Rightarrow$ \"make it right\" $\\Rightarrow$ \"make it fast\". This section discusses approaches to optimize Python code, i.e., make code run faster. The methods presented below are applicable to nearly every programming problem. \n",
    "\n",
    "## 6.0 Timing Code\n",
    "Timing is the first step in measuring code performance.\n",
    "1. In the Jupyter notenook, one can use magic function $\\%timeit$, which can be used to time a single execution statement or a single method. It provides a simple way to time small bits of Python code. (1s = 1000ms, 1ms = 1000$\\mu$s, 1$\\mu$s = 1000ns)\n",
    "2. To time more complicated codes, one can consider the \"timeit\" module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261 µs ± 40.2 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "the execution time is 0.0003791719791479409\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import numpy as np\n",
    "\n",
    "A = np.random.random((100,100))\n",
    "\n",
    "%timeit -n10 np.linalg.inv(A)\n",
    "\n",
    "start = timeit.default_timer()\n",
    "np.linalg.inv(A)\n",
    "end = timeit.default_timer()\n",
    "print(\"the execution time is\", end - start) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Avoiding (Unnecessary) Object Copies\n",
    "Generally speaking, creating and returning object copies have their time and space costs, as Python has to allocate memory for these copies. Whenever it is safe, operating directly on the original object is preferred from an efficiency point of view. \n",
    "### 6.1.1 Using Appropriate Indexing\n",
    "Recall that elements from Numpy arrays can be selected using 4 methods: scalar selection, slicing, numerical (list-of-locations) indexing and logical (Boolean) indexing. Numerical indexing and/or logical indexing create a copy of the original array in the memory, while slicing (scalar selection is a special case) returns a view of an array. This can be easily verified by the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4] [0 1 2] [0 1 2] [0 1 2]\n",
      "[0 2 4 6 8] [0 2 4] [0 1 2] [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(5)\n",
    "a_slicing = a[0:3]\n",
    "a_numerical = a[np.arange(3)]\n",
    "a_logical = a[a < 3]\n",
    "print(a, a_slicing, a_numerical, a_logical)\n",
    "\n",
    "a *= 2\n",
    "print(a, a_slicing, a_numerical, a_logical)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since slicing does not produce copies, using it has some efficiency gains when handling large data (arrays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.7 µs ± 3.25 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "51.6 µs ± 14.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "124 µs ± 8.54 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "def sum_slicing(x):\n",
    "    return np.mean(x[1000:10001])\n",
    "\n",
    "def sum_numerical(x):\n",
    "    return np.mean(x[np.arange(1000,10001)])\n",
    "\n",
    "def sum_logical(x):\n",
    "    return np.mean(x[(x >= 1000) & (x <= 10000)])\n",
    "\n",
    "a = np.arange(100000)\n",
    "\n",
    "%timeit -n100 sum_slicing(a)\n",
    "%timeit -n100 sum_numerical(a)\n",
    "%timeit -n100 sum_logical(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2 Using In-Place Algorithms\n",
    "An in-place algorithm operates directly on its input, instead of creating and returning a new copy of the input. Working in-place is a good way to speed up computation and save memory. However, one should keep in mind that in-place algorithms are \"destructive\" since the original input is changed when it is edited to create the new ouput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24 ms ± 216 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "1.43 ms ± 187 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "A = np.random.random((1000,1000))\n",
    "B = np.random.random((1000,1000))\n",
    "\n",
    "%timeit -n10 global A; A *= B \n",
    "%timeit -n10 A*B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.3 Utilizing Broadcasting \n",
    "When two arrays have different shapes during arithmetic operations, the smaller array is “broadcast” across the larger one so that they are compatible in shape. Broadcasting does not make needless copies of data and usually leads to efficient algorithm implementations. Furthermore, broadcasting provides a way to vectorize array operations so that looping occurs in C instead of Python.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 µs ± 10.6 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n",
      "260 µs ± 24.6 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n",
      "635 µs ± 35.3 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
     ]
    }
   ],
   "source": [
    "A = np.random.random((1000,1))\n",
    "B = np.random.random((1,100))\n",
    "\n",
    "# compute the Kronecker product of A and B\n",
    "%timeit -n50 A*B\n",
    "%timeit -n50 A@np.ones((1,100))*(np.ones((1000,1))@B)\n",
    "%timeit -n50 np.kron(A,B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Avoiding Loops in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 Vectorizing to Avoid Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "5.68 µs ± 1.63 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n",
      "11.1 ms ± 465 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
     ]
    }
   ],
   "source": [
    "A = np.random.random((100,10))\n",
    "B = np.random.random((10,20))\n",
    "\n",
    "# matrix multiplication\n",
    "def f(X,Y):\n",
    "    m,k = X.shape\n",
    "    k,n = Y.shape\n",
    "    Z = np.zeros((m,n))\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            for l in range(k):\n",
    "                Z[i,j] += X[i,l]*Y[l,j]                       \n",
    "    return Z\n",
    "\n",
    "print(np.allclose(f(A,B), A@B))\n",
    "\n",
    "%timeit -n50 A@B\n",
    "%timeit -n50 f(A,B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 Using (Generalized) Universal Functions \n",
    "Universal functions (ufunc) are functions that do element-by-element operations on arrays. Generalized universal functions (gufunc) extend ufunc to support “sub-array” by “sub-array” operations. Many of the built-in functions are implemented in compiled C code, and so the execution is fast. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "68.1 µs ± 11 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n",
      "140 µs ± 9.11 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
     ]
    }
   ],
   "source": [
    "X = np.random.random((100,3,3))\n",
    "Y = np.random.random((100,3,3))\n",
    "\n",
    "print(np.allclose(\n",
    "      np.array([x@y for x,y in zip(X,Y)]), \n",
    "      np.matmul(X,Y)))\n",
    "\n",
    "%timeit -n50 np.matmul(X,Y)\n",
    "%timeit -n50 np.array([x@y for x,y in zip(X,Y)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3 Using Numpy Functions and Array Methods \n",
    "Numpy provides a high-performance multidimensional array object, and tools for working with these arrays. Numpy functions (and according array methods if available) are typically faster than their Python built-in counterparts when processing Numpy arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.22 µs ± 1.93 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "5.71 µs ± 1.09 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "64 µs ± 10.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.random((100,1))\n",
    "\n",
    "%timeit -n100 np.min(x)\n",
    "%timeit -n100 x.min()\n",
    "%timeit -n100 min(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.4 Using List Comprehension and map( )\n",
    "List comprehension and \"map( )\" are built-in methods to apply a function to an iterable. Both are much faster than for loops, but they are dominated by Numpy functions and ufunc/gufunc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912 µs ± 115 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n",
      "733 µs ± 66.3 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n",
      "53.1 µs ± 3.11 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n",
      "1.05 ms ± 80.2 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
     ]
    }
   ],
   "source": [
    "def f_loop(x,y):\n",
    "    z = []\n",
    "    for i in range(len(x)-1):\n",
    "        z.append(max(x[i],y[i]))\n",
    "    return z\n",
    "\n",
    "X = np.random.randint(1, 9, (1000,1))\n",
    "Y = np.random.randint(1, 9, (1000,1))\n",
    "\n",
    "%timeit -n50 list([np.maximum(x,y) for x,y in zip(X,Y)])   # list comprehension\n",
    "%timeit -n50 list(map(np.maximum,X,Y))                     # map()\n",
    "%timeit -n50 np.maximum(X,Y).tolist()                      # ufunc\n",
    "%timeit -n50 f_loop(X,Y)                                   # for loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.5 Using List and Set Methods\n",
    "List/set methods are much faster than loops. Do check available list/set methods before writing a loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "223 µs ± 15.1 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n",
      "2.79 ms ± 99.8 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n",
      "True\n",
      "128 µs ± 3.25 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n",
      "2.11 ms ± 126 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n",
      "True\n",
      "14.5 µs ± 1.83 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n",
      "322 µs ± 27.6 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
     ]
    }
   ],
   "source": [
    "import itertools as it\n",
    "\n",
    "def f_combination(x):\n",
    "    z, n = [], len(x)\n",
    "    \n",
    "    for i in range(n-1):\n",
    "        for j in range(i+1,n):\n",
    "            z.append([x[i],x[j]])\n",
    "    return z\n",
    "\n",
    "v = np.array(range(100))\n",
    "print(np.allclose(f_combination(v), \n",
    "                  list(it.combinations(v, 2))))\n",
    "\n",
    "%timeit -n50 list(it.combinations(x, 2))\n",
    "%timeit -n50 f_combination(x)\n",
    "\n",
    "def f_count(X,x):\n",
    "    c = 0\n",
    "    for i in range(len(X)):\n",
    "        c += X[i] == x\n",
    "    return c\n",
    "\n",
    "X = np.random.randint(0,100,1000)\n",
    "\n",
    "print(f_count(X,9) == list(X).count(9))\n",
    "\n",
    "%timeit -n50 list(X).count(9)\n",
    "%timeit -n50 f_count(X,9)\n",
    "\n",
    "def f_intersection(X,Y):\n",
    "    Z = set([])\n",
    "    for x in X:\n",
    "        if x in Y:\n",
    "            Z.add(x)\n",
    "    return Z\n",
    "\n",
    "A = np.random.randint(0,1000,100)\n",
    "B = np.random.randint(0,1000,100)\n",
    "\n",
    "print(f_intersection(A,B) == set(A).intersection(B))\n",
    "\n",
    "%timeit -n50 set(A).intersection(B)\n",
    "%timeit -n50 f_intersection(A,B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Compiling Python Functions\n",
    "### 6.3.1 Profiling Code\n",
    "For programmer productivity, it often makes sense to identify the code bottlenecks before optimizing the code. This can be done by code profiling. A profiling procedure generates a set of statistics that describes how often and for how long various parts of the code executed. These statistics can then be formatted into reports via the \"pstats\" module. One of basic Python profilers is provided by the \"profile\" module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "A = np.random.random((300,10))\n",
    "B = np.random.random((10,200))\n",
    "\n",
    "def f1(X,Y):\n",
    "    m,k = X.shape\n",
    "    k,n = Y.shape\n",
    "    Z = np.zeros((m,n))\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            for l in range(k):\n",
    "                Z[i,j] += X[i,l]*Y[l,j]                       \n",
    "    return Z\n",
    "\n",
    "def f2(X,Y):\n",
    "    return X@Y\n",
    "\n",
    "def test(X,Y):\n",
    "    f1(X,Y)\n",
    "    f2(X,Y)\n",
    "    \n",
    "import profile\n",
    "profile.run(\"print(test(A,B))\", \"code.profile\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard report created by $profile.run()$ is not very flexible. Custom reports can be produced by saving the raw profiling data and processing it separately with the $pstats.Stats$ class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar  5 23:18:27 2018    code.profile\n",
      "\n",
      "         40 function calls in 0.354 seconds\n",
      "\n",
      "   Random listing order was used\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        0    0.000             0.000          profile:0(profiler)\n",
      "        1    0.000    0.000    0.354    0.354 profile:0(print(test(A,B)))\n",
      "        1    0.000    0.000    0.352    0.352 :0(exec)\n",
      "        1    0.000    0.000    0.352    0.352 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.352    0.352 <ipython-input-31-49b6bb79b942>:17(test)\n",
      "        1    0.351    0.351    0.352    0.352 <ipython-input-31-49b6bb79b942>:4(f1)\n",
      "        1    0.001    0.001    0.001    0.001 :0(zeros)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-31-49b6bb79b942>:14(f2)\n",
      "        1    0.000    0.000    0.000    0.000 :0(print)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/ouyangfu/anaconda3/lib/python3.6/site-packages/ipykernel/iostream.py:342(write)\n",
      "        2    0.000    0.000    0.000    0.000 :0(isinstance)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/ouyangfu/anaconda3/lib/python3.6/site-packages/ipykernel/iostream.py:284(_is_master_process)\n",
      "        2    0.000    0.000    0.000    0.000 :0(getpid)\n",
      "        3    0.000    0.000    0.000    0.000 /Users/ouyangfu/anaconda3/lib/python3.6/site-packages/ipykernel/iostream.py:180(schedule)\n",
      "        3    0.000    0.000    0.000    0.000 /Users/ouyangfu/anaconda3/lib/python3.6/threading.py:1104(is_alive)\n",
      "        3    0.000    0.000    0.000    0.000 /Users/ouyangfu/anaconda3/lib/python3.6/threading.py:506(is_set)\n",
      "        3    0.000    0.000    0.000    0.000 /Users/ouyangfu/anaconda3/lib/python3.6/threading.py:1062(_wait_for_tstate_lock)\n",
      "        3    0.000    0.000    0.000    0.000 :0(acquire)\n",
      "        3    0.000    0.000    0.000    0.000 :0(urandom)\n",
      "        3    0.000    0.000    0.000    0.000 /Users/ouyangfu/anaconda3/lib/python3.6/site-packages/ipykernel/iostream.py:87(_event_pipe)\n",
      "        2    0.000    0.000    0.000    0.000 /Users/ouyangfu/anaconda3/lib/python3.6/site-packages/ipykernel/iostream.py:297(_schedule_flush)\n",
      "        1    0.001    0.001    0.001    0.001 :0(setprofile)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pstats\n",
    "cp = pstats.Stats(\"code.profile\")\n",
    "cp.print_stats()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Jupyter notebook, the profiling can be done with line magic $\\%prun$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "*** Profile stats marshalled to file 'code.profile'. \n",
      "Mon Mar  5 23:19:31 2018    code.profile\n",
      "\n",
      "         7 function calls in 0.357 seconds\n",
      "\n",
      "   Random listing order was used\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.357    0.357 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method numpy.core.multiarray.zeros}\n",
      "        1    0.357    0.357    0.357    0.357 <ipython-input-31-49b6bb79b942>:4(f1)\n",
      "        1    0.000    0.000    0.357    0.357 <ipython-input-31-49b6bb79b942>:17(test)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-31-49b6bb79b942>:14(f2)\n",
      "        1    0.000    0.000    0.357    0.357 <string>:1(<module>)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%prun -q -D code.profile test(A,B)\n",
    "cp = pstats.Stats(\"code.profile\")\n",
    "cp.print_stats()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2 Numba\n",
    "One way to speed up detected code bottlenecks is to compile the code to machine executables, often via an intermediate C or C-like stage. There are two common approaches to compiling Python code - using a Just-In-Time (JIT) compiler and using Cython for Ahead of Time (AOT) compilation. This note mostly covers the JIT approach provided by Numba as it can often significantly speed up Python code with minimal effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.31 µs ± 108 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "18.6 µs ± 694 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "13.5 ms ± 392 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "from numba import jit \n",
    "\n",
    "A = np.random.random((50,10))\n",
    "B = np.random.random((10,50))\n",
    "\n",
    "def F(X,Y):\n",
    "    m,k = X.shape\n",
    "    k,n = Y.shape\n",
    "    Z = np.zeros((m,n))\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            for l in range(k):\n",
    "                Z[i,j] += X[i,l]*Y[l,j]                       \n",
    "    return Z\n",
    "\n",
    "Fjit = jit(F)\n",
    "\n",
    "%timeit A@B\n",
    "%timeit Fjit(A,B)\n",
    "%timeit F(A,B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pure Python loop is slow because\n",
    "1. Python uses a very general approach to process operations. The strength is that many Python opearators apply to a wide range of objects (arrays, strings, lists, etc), while the drawback is that Python has to identify the type of the object and its associated functions/methods in each operation.\n",
    "2. Python treats each loop as independent, i.e., it does not learn from what happened before. This makes Python perform a lot of needless actions that are mostly evitable if it could remember what it did in last loop.\n",
    "\n",
    "The post-JIT code produced by Numba knows substantially more about the structure of the problem. It is natural to think that more efficiency gains can be obtained by providing Numba more information about the problem. This can be done by describing the inputs and outputs (signature specifications)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.4 µs ± 623 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "20.3 µs ± 1.49 µs per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# both output and inputs are 2-D float64 arrays\n",
    "Fjit_descr = jit(\"double[:,:](double[:,:],double[:,:])\")(F)\n",
    "\n",
    "%timeit Fjit_descr(A,B)\n",
    "%timeit Fjit(A,B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba can generate much faster code than pure Python since it only supports a small (but important)\n",
    "set of data types, functions, and operators useful for numerical work. Numba supports two modes of operation: object mode and nopython mode. Object mode is \"robust\" (always works), but normally not obviously faster than pure Python. Nopython mode requires that every command in a function is supported by Numba. When compiling Python code, Numba tries nopython mode first. If it does not work, then Numba falls back to object mode. To prevent Numba from falling back, and instead raise an error, one can pass keyword \"nopython = True\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.5 µs ± 483 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "18.3 µs ± 800 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "Fjit_nopy = jit(F, nopython = True)  \n",
    "\n",
    "%timeit Fjit_nopy(A,B)\n",
    "%timeit Fjit(A,B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.3 Cython\n",
    "When pure Numpy and/or Numba cannot achieve desirable performance improvement, one can try Cython, which is a powerful, but more complex, “optimizing static compiler”. Cython is a superset of Python, and so valid Python code is also valid Cython code. Cython code has a number of advantages over Numba’s JIT (dynamic) compiler:\n",
    "\n",
    "1. Cython modules are statically compiled, and so using a Cython module does not incur a “warm-up” penalty due to JIT compilation. \n",
    "2. Numba is a relatively new, rapidly evolving project, and so code may encounter compatibility problem when executed in different versions.\n",
    "3. A Python extension produced by Cython can be distributed to other users and does not require Cython to be installed. In contrast, Numba must be installed and performance gains may vary across Numba versions.\n",
    "4. Cython can be used interface to existing C/C++ code.\n",
    "\n",
    "Since Numba often provides similar speed-ups with less work (and it is rapidly evolving!), Cython is not covered in this note. The following references might be helpful for studying Cython:\n",
    "\n",
    "1. [Cython](http://docs.cython.org/en/latest/#)\n",
    "2. [Cython: A Guide for Python Programmers](https://www.amazon.com/Cython-Kurt-W-Smith/dp/1491901551)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
